이 공모전은 Kaggle Playground Series 경진대회의 일부로, 다양한 오디오 피쳐를 분석하여 노래의 분당 비트 수, 즉 BPM을 예측하는 회귀 모델 구축을 목표로 합니다. 모델의 성능은 RMSE를 기준으로 평가되며, 이 값이 낮을수록 더 정확한 모델입니다.

발표는 다음과 같은 순서로 진행하겠습니다. 먼저 데이터 로드 후 데이터 탐색, 전처리 및 가공, 스케일과 로그 변환, 그 후 스태킹, 규제, 피쳐 셀렉션 등을 진행했습니다.

학습에 필요없는 id 컬럼을 드랍한 뒤 분석의 편의를 위해 컬럼명을 간단한 약어로 변경하였습니다.

먼저 데이터의 기본적인 특징을 살펴보았습니다. 데이터는 총 52만여 개의 샘플로 구성되어 있으며, 'id' 컬럼을 제외하고 총 10개의 변수가 있습니다. 이 중 9개는 피쳐, 1개는 타겟 변수인 'bpm'입니다. 다행히 결측치는 없었고, 모든 변수는 수치형(float64) 데이터였습니다.

다음으로 각 피쳐의 분포를 히스토그램으로 확인했습니다. 보시는 바와 같이 'vc', 'aq', 'is'와 같은 변수들은 오른쪽으로 심하게 치우친 분포를 보였고, 'al' 변수는 왼쪽으로 약간 치우친 경향을 나타냈습니다. 이렇게 데이터가 한쪽으로 치우쳐 있으면 모델 성능에 영향을 줄 수 있으므로, 추후 로그 변환과 같은 전처리 과정이 필요함을 확인했습니다.

이어서 박스 플롯(Box Plot)을 통해 이상치를 확인했습니다. 대부분의 피쳐에서 IQR 범위를 벗어나는 이상치들이 다수 발견되었습니다. 이러한 이상치들은 모델의 예측을 왜곡시킬 수 있기 때문에, 반드시 처리해야 할 주요 과제로 판단했습니다.

먼저 myscore 공통함수를 만들었습니다.
이 함수는 저희가 수업시간에 썼던 myscore 함수에 현재 RMSE 점수를 역대 최고 점수와 비교하여 최고 기록이 경신되었는지 알려주는 기능과 Feature Importance를 시각화하는 기능을 추가했습니다.

본격적인 전처리에 앞서, 원본 데이터를 그대로 XGBoost 모델에 학습시켜 기준 성능을 측정했습니다. 그 결과, 베이스라인 모델의 RMSE는 약 26.51로 측정되었습니다.

이상치 처리 방법으로 데이터를 삭제하는 'Trimming'과 경계값으로 대체하는 'Winsorization' 두 가지를 고려했습니다. 데이터 손실을 최소화하기 위해 저희는 'Winsorization'을 선택하여 이상치를 경계값으로 대체했습니다. 그 결과, RMSE 점수가 26.51에서 26.46으로 소폭 개선되는 효과를 확인했습니다.
추가로 IQR을 사용했음에도 불구하고 이상치가 여전히 존재하여 발표 자료에 합치지는 못했지만 따로 이상치를 직접 제거해보았고 그 결과 제거 전 데이터 수가 52만건에서 제거 후 11만건으로 감소하였고 분포도를 찍어본 결과 이상치가 확실히 제거된 걸 확인할 수 있었습니다.

다음으로, 기존 피쳐들을 조합하여 새로운 의미를 갖는 7개의 파생 피쳐를 생성했습니다. 예를 들어, 'tdm'(트랙 길이, 밀리초)을 분 단위로 변환한 'tdn'이나, 보컬과 악기의 균형을 나타내는 'vib'와 같은 변수들입니다. 이 파생 피쳐들을 추가한 결과, RMSE가 26.46에서 26.459로 추가적으로 개선되었습니다.

가장 효과적인 모델과 스케일러 조합을 찾기 위해 모델은 XGBoost와 LightGBM을, 스케일러는 MinMaxScaler, RobustScaler, StandardScaler 세 가지를 사용했습니다. 피쳐와 타겟 변수를 모두 스케일링하여 총 6개 조합의 성능을 비교한 결과, LightGBM 모델과 MinMaxScaler 조합이 RMSE 26.35로 가장 우수한 성능을 보였습니다.

현재까지의 분석 결과를 종합하여 중간 제출용 모델 파이프라인을 구성했습니다. 이 파이프라인은 (1) 이상치를 경계값으로 대체하고, (2) 7개의 파생 피쳐를 추가한 뒤, (3) TransformedTargetRegressor를 사용해 피쳐와 타겟을 모두 MinMaxScaler로 스케일링하고, (4) 최종적으로 LightGBM 모델로 예측하는 과정으로 이루어집니다.
그 결과 Validation RMSE는 26.63803, Submission RMSE는 26.41156이 나왔습니다.

이후, 개별 모델의 예측을 결합하여 더 나은 결과를 만드는 스태킹 앙상블을 시도했습니다. 기반 모델은 GPU 사용으로 설정된 XGBoost와 LightGBM을 사용했고 메타 모델은 간단하면서도 규제 효과가 있는 Ridge를 선택했습니다.
이 두 기반 모델과 메타 모델을 조합하여 스태킹 모델을 구성하고 학습시킨 결과, Validation RMSE는 26.354로 단일 모델에 비해 큰 성능 향상을 보이지는 않았습니다.
그 결과 Validation RMSE는 26.63803, Submission RMSE는 26.64300이 나왔습니다.

다음으로 L1과 L2 규제를 모두 사용하는 ElasticNet의 규제 강도, 즉 alpha 값을 0.01부터 100까지 변경하며 테스트했습니다. 각 alpha 값에 대해 데이터 스케일링과 모델 학습을 파이프라인으로 묶고, myscore 함수로 성능을 평가했습니다.
그 결과, alpha 값이 0.01일 때 Validation RMSE가 26.35653으로 가장 좋은 성능을 보였습니다. 이는 LightGBM 단일 모델과 비슷한 수준의 성능으로 나왔습니다.
Kaggle에서의 Submission RMSE는 26.41590으로 전의 RMSE보다 더 나은 스코어가 나왔습니다.

추가로 모델의 복잡도를 낮추고 과적합을 방지하기 위해 Ridge 모델 기반의 피처 셀렉션을 적용했습니다. SelectFromModel을 사용하여 Ridge 모델의 중요도가 전체 피처의 중앙값보다 큰 피처들만 선택하도록 설정했습니다.
그 결과 총 16개의 피처 중 중요도가 높은 상위 8개의 피처가 선택되었고 선택된 피처들만 사용하여 최종 모델을 구성하고 제출 파일을 생성하는 파이프라인을 구축했습니다. 피쳐 셀렉션 후 Kaggle에서의 Submission RMSE는 26.41824로 전의 스코어보다 소폭 하향된 스코어가 나왔습니다.

마지막으로 XGB와 LGBM을 기반 모델로, Ridge를 메타 모델로 사용하는 스태킹 앙상블을 사용했고 하이퍼파라미터 튜닝을 위해 RandomizedSearchCV와 KFold 교차 검증을 사용했으며 모델 평가는 RMSE 점수를 기준으로 가장 좋은 조합을 탐색했습니다.
그 결과 Kaggle에서의 Submission RMSE는 26.40891로 제일 좋은 스코어가 나왔습니다. 이로써 전체 2534명 중 1282등으로 상위 50%의 기록으로 마감했습니다.

이상으로 발표를 마치겠습니다.